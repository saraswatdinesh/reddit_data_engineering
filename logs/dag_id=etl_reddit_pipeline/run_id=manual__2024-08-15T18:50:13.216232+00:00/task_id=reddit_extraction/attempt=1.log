[2024-08-15T18:50:14.970+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-08-15T18:50:14.992+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-15T18:50:13.216232+00:00 [queued]>
[2024-08-15T18:50:15.002+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-15T18:50:13.216232+00:00 [queued]>
[2024-08-15T18:50:15.003+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-08-15T18:50:15.013+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-08-15 18:50:13.216232+00:00
[2024-08-15T18:50:15.029+0000] {standard_task_runner.py:64} INFO - Started process 86 to run task
[2024-08-15T18:50:15.039+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-08-15T18:50:13.216232+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmpv80jc74r']
[2024-08-15T18:50:15.054+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask reddit_extraction
[2024-08-15T18:50:15.287+0000] {task_command.py:426} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-08-15T18:50:13.216232+00:00 [running]> on host 15d5e5353726
[2024-08-15T18:50:15.463+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Dinesh Saraswat' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-08-15T18:50:13.216232+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-08-15T18:50:13.216232+00:00'
[2024-08-15T18:50:15.465+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-08-15T18:50:15.491+0000] {logging_mixin.py:188} INFO - Connected to reddit!
[2024-08-15T18:50:16.610+0000] {logging_mixin.py:188} INFO - [{'id': '1esertq', 'title': 'Recently completed Designing Data Intensive Applications - Where should I go from here?', 'score': 64, 'num_comments': 21, 'author': Redditor(name='Square-Mulberry1301'), 'created_utc': 1723674681.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esertq/recently_completed_designing_data_intensive/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1est8pl', 'title': 'Best way to build a Small Data Lake? (<100GB)', 'score': 35, 'num_comments': 37, 'author': Redditor(name='2minutestreaming'), 'created_utc': 1723722935.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1est8pl/best_way_to_build_a_small_data_lake_100gb/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esqc5z', 'title': 'Does Data Engineering Matter for Startups?', 'score': 29, 'num_comments': 25, 'author': Redditor(name='No-Sympathy9824'), 'created_utc': 1723711982.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esqc5z/does_data_engineering_matter_for_startups/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esszbv', 'title': 'If youâ€™re using dbt for transformations, what data viz tool does your org use?', 'score': 14, 'num_comments': 29, 'author': Redditor(name='Rajsuomi'), 'created_utc': 1723722095.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esszbv/if_youre_using_dbt_for_transformations_what_data/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1et17ur', 'title': 'I get bored once we reach the "mature" stage. Help.', 'score': 14, 'num_comments': 4, 'author': Redditor(name='ntdoyfanboy'), 'created_utc': 1723743276.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1et17ur/i_get_bored_once_we_reach_the_mature_stage_help/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1eswldu', 'title': "When it's time to upgrade from SharePoint Online to a more elegant database?", 'score': 7, 'num_comments': 10, 'author': Redditor(name='Ceborn'), 'created_utc': 1723732051.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eswldu/when_its_time_to_upgrade_from_sharepoint_online/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esib05', 'title': 'jsonlines in spark, scala udf', 'score': 7, 'num_comments': 8, 'author': Redditor(name='bcsamsquanch'), 'created_utc': 1723684162.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esib05/jsonlines_in_spark_scala_udf/', 'over_18': False, 'edited': 1723687123.0, 'spoiler': False, 'stickied': False}, {'id': '1esxs7u', 'title': 'Anyone attending the dbt Coalesce conference this year?', 'score': 4, 'num_comments': 1, 'author': Redditor(name='MasterKluch'), 'created_utc': 1723734932.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esxs7u/anyone_attending_the_dbt_coalesce_conference_this/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esut7g', 'title': 'Exposing Data for Customers', 'score': 5, 'num_comments': 5, 'author': Redditor(name='onmywaytostealyagirl'), 'created_utc': 1723727504.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esut7g/exposing_data_for_customers/', 'over_18': False, 'edited': 1723727807.0, 'spoiler': False, 'stickied': False}, {'id': '1et0m9n', 'title': 'Efficient replacement for Pyspark Union', 'score': 3, 'num_comments': 12, 'author': Redditor(name='Easy-Experience6270'), 'created_utc': 1723741829.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1et0m9n/efficient_replacement_for_pyspark_union/', 'over_18': False, 'edited': 1723746117.0, 'spoiler': False, 'stickied': False}, {'id': '1esz5fz', 'title': 'explain the final steps after the data catalog please', 'score': 4, 'num_comments': 0, 'author': Redditor(name='jimbochong'), 'created_utc': 1723738224.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esz5fz/explain_the_final_steps_after_the_data_catalog/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esmgne', 'title': 'Any idea for AWS data platform project with some other data tools out there intergrated ?', 'score': 4, 'num_comments': 2, 'author': Redditor(name='Tuan_coder'), 'created_utc': 1723696775.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esmgne/any_idea_for_aws_data_platform_project_with_some/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1eswzyv', 'title': 'Data modelling recommendation starwars api', 'score': 3, 'num_comments': 1, 'author': Redditor(name='No-Conversation476'), 'created_utc': 1723733027.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1eswzyv/data_modelling_recommendation_starwars_api/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1et1ljx', 'title': 'Mariadb crashes after large queries ', 'score': 2, 'num_comments': 0, 'author': Redditor(name='Luemas91'), 'created_utc': 1723744205.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1et1ljx/mariadb_crashes_after_large_queries/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esoazf', 'title': 'What do you think about automating data requests from non-technical people?', 'score': 0, 'num_comments': 4, 'author': Redditor(name='B7456-A5'), 'created_utc': 1723703621.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esoazf/what_do_you_think_about_automating_data_requests/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esmezg', 'title': 'Help: Seeking Advice on Optimizing Data Pipeline for Sentiment Analysis, NER Tagging, and Custom AI/ML Workflows', 'score': 2, 'num_comments': 1, 'author': Redditor(name='Unstable007'), 'created_utc': 1723696618.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esmezg/help_seeking_advice_on_optimizing_data_pipeline/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esekmm', 'title': 'Looking for advice on landing junior data engineer roles', 'score': 2, 'num_comments': 6, 'author': Redditor(name='draktor99'), 'created_utc': 1723674168.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esekmm/looking_for_advice_on_landing_junior_data/', 'over_18': False, 'edited': 1723688649.0, 'spoiler': False, 'stickied': False}, {'id': '1esbabh', 'title': 'Snowflake, Airbyte and DBT - Managing multiple workspaces and databases', 'score': 2, 'num_comments': 3, 'author': Redditor(name='PLxFTW'), 'created_utc': 1723665983.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esbabh/snowflake_airbyte_and_dbt_managing_multiple/', 'over_18': False, 'edited': 1723667424.0, 'spoiler': False, 'stickied': False}, {'id': '1esa0ba', 'title': 'On The Fence Between a DS and DE Career at the 3 YOE Mark', 'score': 2, 'num_comments': 1, 'author': Redditor(name='ParticularBattle2713'), 'created_utc': 1723662384.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esa0ba/on_the_fence_between_a_ds_and_de_career_at_the_3/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1es8sy8', 'title': 'Updating data storage in parquet on S3', 'score': 2, 'num_comments': 16, 'author': Redditor(name='soyelsimo963'), 'created_utc': 1723659430.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1es8sy8/updating_data_storage_in_parquet_on_s3/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esrc88', 'title': 'Airbnb Data Tech Stack', 'score': 1, 'num_comments': 1, 'author': Redditor(name='mjfnd'), 'created_utc': 1723716120.0, 'url': 'https://www.junaideffendi.com/p/airbnb-data-tech-stack?r=cqjft&utm_campaign=post&utm_medium=web', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esocsy', 'title': 'Open source data pipelines', 'score': 2, 'num_comments': 3, 'author': Redditor(name='Aggressive-Bee-8748'), 'created_utc': 1723703828.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esocsy/open_source_data_pipelines/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1esnk9i', 'title': 'Machine learning with Airflow', 'score': 1, 'num_comments': 2, 'author': Redditor(name='unmasked_crusader'), 'created_utc': 1723700756.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1esnk9i/machine_learning_with_airflow/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}, {'id': '1es9n7a', 'title': 'airbyte authorization?', 'score': 1, 'num_comments': 6, 'author': Redditor(name='Wise_Tutor892'), 'created_utc': 1723661489.0, 'url': 'https://www.reddit.com/r/dataengineering/comments/1es9n7a/airbyte_authorization/', 'over_18': False, 'edited': False, 'spoiler': False, 'stickied': False}]
[2024-08-15T18:50:16.611+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-08-15T18:50:16.612+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-08-15T18:50:16.620+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, run_id=manual__2024-08-15T18:50:13.216232+00:00, execution_date=20240815T185013, start_date=20240815T185014, end_date=20240815T185016
[2024-08-15T18:50:16.653+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-08-15T18:50:16.678+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-08-15T18:50:16.679+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
